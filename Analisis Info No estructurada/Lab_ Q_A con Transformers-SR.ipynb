{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q&A con Transformers\n",
    "\n",
    "Haz preguntas al texto utilizando tranformers. Prueba también en distintos idiomas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "contexto = \"\"\"El Real Monasterio de San Lorenzo de El Escorial es un complejo que incluye un palacio real, una basílica, un panteón, una biblioteca, un colegio y un monasterio. Se encuentra en la localidad española de San Lorenzo de El Escorial, en la Comunidad de Madrid, y fue construido en el siglo xvi entre 1563 y 1584.\n",
    "\n",
    "El palacio fue residencia de la familia real española, la basílica es lugar de sepultura de los reyes de España y el monasterio –fundado por monjes de la Orden de San Jerónimo– está ocupado actualmente por frailes de la Orden de San Agustín. Es una de las más singulares arquitecturas renacentistas de España y de Europa. Situado en San Lorenzo de El Escorial, ocupa una superficie de 33.327 m², sobre la ladera meridional del monte Abantos, a 1028 m de altitud, en la sierra de Guadarrama. Está gestionado por Patrimonio Nacional.\n",
    "\n",
    "Conocido también como Monasterio de San Lorenzo El Real, o, sencillamente, El Escorial, fue ideado en la segunda mitad del siglo xvi por el rey Felipe II y su arquitecto Juan Bautista de Toledo, aunque posteriormente intervinieron Juan de Herrera, Juan de Minjares, Giovanni Battista Castello El Bergamasco y Francisco de Mora. El rey concibió un gran complejo multifuncional, monacal y palaciego que, plasmado por Juan Bautista de Toledo según el paradigma de la Traza Universal, dio origen al estilo herreriano.\n",
    "\n",
    "Fue considerado, desde finales del siglo xvi, la Octava Maravilla del Mundo, tanto por su tamaño y complejidad funcional como por su enorme valor simbólico. Su arquitectura marcó el paso del plateresco renacentista al clasicismo desornamentado. Obra ingente, de gran monumentalidad, es también un receptáculo de las demás artes. Sus pinturas, esculturas, cantorales, pergaminos, ornamentos litúrgicos y demás objetos suntuarios, sacros y áulicos hacen que El Escorial sea también un museo. Su compleja iconografía e iconología ha merecido las más variadas interpretaciones de historiadores, admiradores y críticos. El Escorial es la cristalización de las ideas y de la voluntad de su impulsor, el rey Felipe II, un príncipe renacentista.\n",
    "\n",
    "El 2 de noviembre de 1984, la UNESCO declaró el Monasterio y Sitio de El Escorial como Patrimonio de la Humanidad. Es una de las principales atracciones turísticas de la Comunidad de Madrid. El conjunto monumental recibe más de 500 000 visitantes al año.1​\"\"\"\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/codespace/.cache/huggingface/hub/models--mrm8488--distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es/snapshots/dcadd98e59cd7ce8efd00cb4c61a024e2895b4c1/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es\",\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.35.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31002\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/codespace/.cache/huggingface/hub/models--mrm8488--distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es/snapshots/dcadd98e59cd7ce8efd00cb4c61a024e2895b4c1/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es\",\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.35.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31002\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/codespace/.cache/huggingface/hub/models--mrm8488--distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es/snapshots/dcadd98e59cd7ce8efd00cb4c61a024e2895b4c1/pytorch_model.bin\n",
      "Some weights of the model checkpoint at mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertForQuestionAnswering were initialized from the model checkpoint at mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n",
      "loading configuration file config.json from cache at /home/codespace/.cache/huggingface/hub/models--mrm8488--distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es/snapshots/dcadd98e59cd7ce8efd00cb4c61a024e2895b4c1/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es\",\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.35.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31002\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /home/codespace/.cache/huggingface/hub/models--mrm8488--distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es/snapshots/dcadd98e59cd7ce8efd00cb4c61a024e2895b4c1/vocab.txt\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /home/codespace/.cache/huggingface/hub/models--mrm8488--distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es/snapshots/dcadd98e59cd7ce8efd00cb4c61a024e2895b4c1/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /home/codespace/.cache/huggingface/hub/models--mrm8488--distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es/snapshots/dcadd98e59cd7ce8efd00cb4c61a024e2895b4c1/tokenizer_config.json\n",
      "loading file tokenizer.json from cache at None\n",
      "loading configuration file config.json from cache at /home/codespace/.cache/huggingface/hub/models--mrm8488--distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es/snapshots/dcadd98e59cd7ce8efd00cb4c61a024e2895b4c1/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es\",\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.35.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31002\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.005309229250997305,\n",
       " 'start': 1340,\n",
       " 'end': 1359,\n",
       " 'answer': 'estilo herreriano.'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Important!: By now the QA pipeline is not compatible with fast tokenizer, but they are working on it. So that pass the object to the tokenizer {\"use_fast\": False} as in the following example:\n",
    "\n",
    "nlp = pipeline(\n",
    "    'question-answering', \n",
    "    model='mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es',\n",
    "    tokenizer=(\n",
    "        'mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es',  \n",
    "        {\"use_fast\": False}\n",
    "    )\n",
    ")\n",
    "\n",
    "nlp(\n",
    "    {\n",
    "        'question': '¿Para qué lenguaje está trabajando?',\n",
    "        'context': contexto\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.12200357764959335,\n",
       " 'start': 282,\n",
       " 'end': 311,\n",
       " 'answer': 'siglo xvi entre 1563 y 1584.'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\n",
    "    {\n",
    "        'question': '¿Cuanto tardo en ser construido?',\n",
    "        'context': contexto\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122.855364,
   "position": {
    "height": "40px",
    "left": "893.636px",
    "right": "20px",
    "top": "120px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
