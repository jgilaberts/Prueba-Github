{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación supervisada\n",
    "\n",
    "\n",
    "El reto que se va a resolver, es la clasificación de reseñas de hoteles de Andalucía en el sentimiento asociado a la visita. Los textos se encuentran en el dataset `andalucia_hoteles.csv`en la columna `review_text`, y el sentimiento en la columna `label`.\n",
    "\n",
    "Considera también detectar el idioma y filtrar por aquellas reviews que sean en español\n",
    "\n",
    "La clasificación supervisada en textos funciona conceptualmente de manera similar a la clasificación en otros problemas de Machine Learning con datos estructurados:\n",
    "\n",
    "1. Se requiere preprocesar la información (en el caso de datos no estructurados, convertir los textos a TFIDF).\n",
    "2. Dividir en entrenamiento y test el conjunto de textos.\n",
    "3. Entrenar al modelo incluyendo el set de train.\n",
    "4. Evaluación del modelo, lanzando la predicción sobre el conjunto de test y evaluándolo con los valores reales.\n",
    " Puedes hacerlo en notebooks diferentes (cada uno de los modelos) o todos en el mismo. Sigue la secuencia de pasos anterior, aplicando correctamente las funciones necesarias en cada paso, para cada uno de los modelos:\n",
    "\n",
    "- Clasificador ingenuo bayesiano\n",
    "- SVM\n",
    "- KNN\n",
    "- Decision tree\n",
    "- Random Forest\n",
    "- GBT\n",
    "\n",
    "¿Cuál funciona mejor? ¿En qué métricas te has basado?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/irene/opt/anaconda3/envs/nlp/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-09-16 12:00:25.606567: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "## Importación de librerías\n",
    "\n",
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "nlp_español = spacy.load('es_core_news_lg')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                 title  rating  \\\n",
      "0           0                   IMPOSIBLE DESCANSAR       2   \n",
      "1           1          No es oro todo lo que reluce       3   \n",
      "2           2        Un buen hotel con mucho ruido.       3   \n",
      "3           3  SIN CALEFACCIÓN OPERATIVA Y CON FRÍO       2   \n",
      "4           4             Deja bastante que desear.       2   \n",
      "\n",
      "                                         review_text  \\\n",
      "0  El fin de semana mi pareja y yo hicimos una re...   \n",
      "1  El hotel en general está bien, las habtiacione...   \n",
      "2  El hotel es moderno, amplio y limpio, pero no ...   \n",
      "3  Calefacción averiada o no operativa. Se coment...   \n",
      "4  Este hotel ha bajado notoriamente su categoria...   \n",
      "\n",
      "                                location                hotel  label  \n",
      "0  Seville_Province_of_Seville_Andalucia  Hotel_Rey_Alfonso_X      0  \n",
      "1  Seville_Province_of_Seville_Andalucia  Hotel_Rey_Alfonso_X      3  \n",
      "2  Seville_Province_of_Seville_Andalucia  Hotel_Rey_Alfonso_X      3  \n",
      "3  Seville_Province_of_Seville_Andalucia        Melia_Sevilla      0  \n",
      "4  Seville_Province_of_Seville_Andalucia        Melia_Sevilla      0  \n",
      "(7615, 7)\n",
      "Index(['Unnamed: 0', 'title', 'rating', 'review_text', 'location', 'hotel',\n",
      "       'label'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "## Lectura de datos\n",
    "\n",
    "datos = pd.read_csv('data/andalucia_hoteles.csv')\n",
    "print(datos.head())\n",
    "print(datos.shape)\n",
    "print(datos.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Preprocesamiento y normalización\n",
    "Vamos a separar los documentos y sus categorías. docs y categs son series de Pandas. Hay que separar las categorías de los documentos para usar estos últimos y obtener la matriz Tf-idf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = datos['review_text'] # extract column with review\n",
    "categs = datos['label'] # extract column with sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       El fin de semana mi pareja y yo hicimos una re...\n",
       "1       El hotel en general está bien, las habtiacione...\n",
       "2       El hotel es moderno, amplio y limpio, pero no ...\n",
       "3       Calefacción averiada o no operativa. Se coment...\n",
       "4       Este hotel ha bajado notoriamente su categoria...\n",
       "                              ...                        \n",
       "7610    Bastante cerca del centro de sevilla, servicio...\n",
       "7611    Séjour touristique à Séville, la découverte de...\n",
       "7612    Stayed here for 4 nights,  the room was big an...\n",
       "7613    Séjour touristique à Séville, la découverte de...\n",
       "7614    Stayed here for 4 nights,  the room was big an...\n",
       "Name: review_text, Length: 7615, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos es tipo:  <class 'pandas.core.frame.DataFrame'>\n",
      "Docs es tipo:  <class 'pandas.core.series.Series'>\n",
      "Categs es tipo:  <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Datos es tipo: \", type(datos))\n",
    "print(\"Docs es tipo: \", type(docs))\n",
    "print(\"Categs es tipo: \", type(categs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Obtención de las matrices BOW y Tf-idf\n",
    "\n",
    "Obten la matriz TFIDF de todos los textos. Se puede obtener a partir de la matriz BOW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizamos los documentos y convertimos en matriz BOW\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "docs_bow = vectorizer.fit_transform(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'El fin de semana mi pareja y yo hicimos una reserva en este hotel, con el fin de descansar y desconectar, fue sólo una noche y menos mal.  Nos llevaron a un ala bastante apartada del hotel porque nos dijeron que era mejor para descansar ya que la parte de fuera era muy “jaleosa”. Nos pareció bien porque era justo lo que buscábamos, y cuál fue nuestra sorpresa? Desde las 6 de la mañana con ruidos, primero lo que suponemos que eran unos tacones en la habitación de arriba (de eso no tiene culpa el hotel, obviamente) y después sobre las 7 o poco más, las limpiadoras moviendo muebles y arrastrando sofás o lo que fuera. Habíamos cogido sólo alojamiento para descansar, pensando en no tener que madrugar como habitualmente, pero fue IMPOSIBLE por los ruidos constantes.  Por destacar algo…'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construimos la matriz formato Tf-idf\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf = TfidfTransformer() \n",
    "docs_tfidf = tfidf.fit_transform(docs_bow)\n",
    "docs_tfidf_densa = docs_tfidf.todense()\n",
    "docs_tfidf_densa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preparación de los subconjuntos de entrenamiento y test\n",
    "\n",
    "Divide entre train y test, utilizando train_test_split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# División mediante train_test_split. Test de 25%\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "docs_train, docs_test, categs_train, categs_test = train_test_split(docs_tfidf, categs, test_size = 0.25, \n",
    "                                                                    random_state = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Entrenamiento del modelo: clasificador ingenuo bayesiano (MultinomialNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenamiento del clasificador NB\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(docs_train, categs_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluación del modelo.\n",
    "\n",
    "Obtén la confusión matrix para evaluar el rendimiento del modelo, así como el accuracy (utilizando la función score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicción del set de test\n",
    "\n",
    "categs_pred = clf.predict(docs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[612,   8,  46],\n",
       "       [  7, 645,  10],\n",
       "       [157,  62, 357]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(categs_test, categs_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy entrenamiento:  0.9103484503589564\n",
      "Accuracy PRUEBA:  0.8476890756302521\n",
      "Fiabilidad:  0.9311699001585632\n"
     ]
    }
   ],
   "source": [
    "acc_train = clf.score(docs_train, categs_train)\n",
    "acc_test = clf.score(docs_test, categs_test)\n",
    "\n",
    "print(\"Accuracy entrenamiento: \", acc_train)\n",
    "print(\"Accuracy PRUEBA: \", acc_test)\n",
    "print(\"Fiabilidad: \", acc_test / acc_train)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy entrenamiento:  0.9711083873227105\n",
      "Accuracy PRUEBA:  0.8802521008403361\n",
      "Fiabilidad:  0.9064406325097656\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento del clasificador SVM\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel='linear')\n",
    "# svm = SVC(kernel='poly')\n",
    "# svm = SVC(kernel='rbf')\n",
    "# svm = SVC(kernel='sigmoid')\n",
    "\n",
    "\n",
    "svm.fit(docs_train, categs_train)\n",
    "\n",
    "acc_train = svm.score(docs_train, categs_train)\n",
    "acc_test = svm.score(docs_test, categs_test)\n",
    "\n",
    "print(\"Accuracy entrenamiento: \", acc_train)\n",
    "print(\"Accuracy PRUEBA: \", acc_test)\n",
    "print(\"Fiabilidad: \", acc_test / acc_train)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento del clasificador KNN\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "print(\"Númro de vecinos cercanos a considerar: \")\n",
    "num_vecinos = int(input())\n",
    "knn = KNeighborsClassifier(num_vecinos)\n",
    "\n",
    "knn.fit(docs_train, categs_train)\n",
    "\n",
    "acc_train = svm.score(docs_train, categs_train)\n",
    "acc_test = svm.score(docs_test, categs_test)\n",
    "\n",
    "print(\"Accuracy entrenamiento: \", acc_train)\n",
    "print(\"Accuracy PRUEBA: \", acc_test)\n",
    "print(\"Fiabilidad: \", acc_test / acc_train)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Árbol de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento del clasificador Árboles de Decisión\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "a_dec = tree.DecisionTreeClassifier()\n",
    "a_dec.fit(docs_train, categs_train)\n",
    "\n",
    "acc_train = a_dec.score(docs_train, categs_train)\n",
    "acc_test = a_dec.score(docs_test, categs_test)\n",
    "\n",
    "print(\"Accuracy entrenamiento: \", acc_train)\n",
    "print(\"Accuracy PRUEBA: \", acc_test)\n",
    "print(\"Fiabilidad: \", acc_test / acc_train)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122.84136400000001,
   "position": {
    "height": "222.841px",
    "left": "730.622px",
    "right": "20px",
    "top": "7.99999px",
    "width": "310px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "107fb03afb2754bdb3cdbb13c1c83d7d6037442339c22e5ee8cf40869e8513c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
