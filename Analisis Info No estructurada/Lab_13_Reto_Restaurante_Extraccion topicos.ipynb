{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica de Laboratorio en NLP - Tópicos\n",
    "Tema: Extracción de tópicos\n",
    "\n",
    "Introducción:\n",
    "\n",
    "En esta práctica, trabajaremos en un proyecto de análisis de reclamaciones de un restaurante. La empresa desea saber de qué se quejan más los comensales, para identificar áreas de mejora. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importación de librerías\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "nlp = spacy.load(\"es_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentencias = [\n",
    "    \"La comida llegó fría y tardó mucho en ser servida.\",\n",
    "    \"El servicio fue lento y el personal parecía desinteresado.\",\n",
    "    \"Pedimos un plato vegetariano y nos trajeron uno con carne.\",\n",
    "    \"Las mesas estaban sucias y no habían sido limpiadas correctamente.\",\n",
    "    \"No había suficiente iluminación en el área de comedor.\",\n",
    "    \"El restaurante estaba abarrotado y no se respetaron las reservas.\",\n",
    "    \"La música estaba demasiado alta y no se podía mantener una conversación.\",\n",
    "    \"La bebida que pedimos nunca llegó a la mesa.\",\n",
    "    \"Los platos estaban mal sazonados y carecían de sabor.\",\n",
    "    \"El menú tenía errores de ortografía y gramática.\",\n",
    "    \"El restaurante tenía un olor desagradable.\",\n",
    "    \"No había opciones vegetarianas en el menú.\",\n",
    "    \"Se nos cobró de más en la factura.\",\n",
    "    \"El baño del restaurante estaba sucio y sin papel higiénico.\",\n",
    "    \"El vino que pedimos estaba agrio y parecía estar mal almacenado.\",\n",
    "    \"La carne de mi plato estaba cruda en el centro.\",\n",
    "    \"Las sillas eran incómodas y difíciles de mover.\",\n",
    "    \"El personal fue grosero y poco atento.\",\n",
    "    \"El restaurante estaba demasiado caliente y sin aire acondicionado.\",\n",
    "    \"No se nos proporcionaron utensilios de mesa ni servilletas.\",\n",
    "    \"El postre que pedimos estaba rancio y no era comestible.\",\n",
    "    \"El menú era limitado y no ofrecía opciones para alergias alimentarias.\",\n",
    "    \"El restaurante tenía una plaga de insectos.\",\n",
    "    \"Los platos se veían descuidados y mal presentados.\",\n",
    "    \"La factura tenía errores en los cálculos de los precios.\"\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "wpt = nltk.WordPunctTokenizer()\n",
    "stop_words = nltk.corpus.stopwords.words('spanish')\n",
    "\n",
    "\n",
    "def normalize_document(doc):\n",
    "    # lower case and remove special characters\\whitespaces\n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "    # tokenize document\n",
    "    tokens = wpt.tokenize(doc)\n",
    "    # filter stopwords out of document\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    # re-create document from filtered tokens\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc\n",
    "\n",
    "norm_corpus=[]\n",
    "\n",
    "for document in sentencias:\n",
    "    norm_corpus.append(normalize_document(document))\n",
    "\n",
    "norm_corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creación del vectorizador y generación de la matriz Tf-idf\n",
    "\n",
    "tfifd_vec = TfidfVectorizer()\n",
    "\n",
    "TFIDF = tfifd_vec.fit_transform(norm_corpus)\n",
    "\n",
    "TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de la matriz\n",
    "\n",
    "# Obtenemos el vocabulario para poner las etiquetas de las columnaas\n",
    "vocab = tfifd_vec.get_feature_names()\n",
    "\n",
    "print(\"Palabras en el vocabulario: \", len(vocab))\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y construimos un dataframe para mostrar el resultado: por cada documento las ocurrencias de cada token\n",
    "pd.DataFrame(TFIDF.toarray(), columns=vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación de LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación de un objeto de clase LDA con sus componentes\n",
    "lda_model = LatentDirichletAllocation(n_components = 3, max_iter = 20, random_state = 20)\n",
    "\n",
    "# Extracción de los tópicos\n",
    "X_topics = lda_model.fit_transform(TFIDF)\n",
    "\n",
    "topic_words = lda_model.components_\n",
    "topic_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Palabras en cada tópico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Número de palabras a extraer de cada tópico\n",
    "\n",
    "n_top_words = 5\n",
    "\n",
    "for i, topic_dist in enumerate(topic_words):\n",
    "    \n",
    "    sorted_topic_dist = np.argsort(topic_dist)\n",
    "    \n",
    "    topic_words = np.array(vocab)[sorted_topic_dist]\n",
    "    \n",
    "    topic_words = topic_words[:-n_top_words:-1]\n",
    "    print (\"Tópico\", str(i+1), topic_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribución de documentos por tópico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_topic = lda_model.transform(TFIDF)  \n",
    "\n",
    "for n in range(doc_topic.shape[0]):\n",
    "    topic_doc = doc_topic[n].argmax()\n",
    "    print (\"Documento\", n+1, \" -- Tópico:\" ,topic_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cómo visualizar los tópicos en el espacio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa las bibliotecas necesarias\n",
    "import pyLDAvis.sklearn\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import pyLDAvis\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Prepara los datos para PyLDAvis\n",
    "panel = pyLDAvis.sklearn.prepare(lda_model, TFIDF, TFIDFVectorizer, mds='tsne')\n",
    "\n",
    "# Visualiza el modelo LDA\n",
    "pyLDAvis.display(panel)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122.84136400000001,
   "position": {
    "height": "40px",
    "left": "1184.55px",
    "right": "20px",
    "top": "120px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "6d3789d190ebbe556da5f43ea86e3cac1eb49030905bcb870a33d67b8051f235"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
