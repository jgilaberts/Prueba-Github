{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad 2 Analisis de Informacion No Estructurada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# - Javier Gilabert Sabater"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. LeaelcontenidodelficherocsvenunDataFrame.\n",
    "2. Realiceelpre-procesamientoqueconsiderenecesario.Puede\n",
    "utilizar funciones de la librería NLTK o spaCy, a su voluntad. Recomendamos una escritura modular del código, para poder hacer pruebas posteriormente, y contestar a las preguntas del punto 6.\n",
    "3. Convierta el corpus de documentos en una matriz TF-idf.\n",
    "4. Dividaenunsubconjuntodeentrenamientoyotrodeevaluación.\n",
    "5. Llegadosaestepunto,realicemodelosdeentrenamientoalmenos\n",
    "con algoritmos de clasificador bayesiano ingenuo, máquinas SVM y un modelo basado en árbol de decisión. Obtenga resultados de accuracy de la clasificación, así como las matrices de confusión para los tres modelos.\n",
    "6. Contestealassiguientespreguntasbasándoteenevidenciasde código. ¿Tiene influencia en el resultado final el número máximo de features a utilizar? Prueba al menos dos números de features diferentes para los tres algoritmos y mide los resultados. ¿Modifica el resultado si no se eliminan las stop words? Pruébalo para los tres algoritmos y mide los resultados.\n",
    "7. Imagínesequeesteentregableesunalaborquelehansolicitadoen un entorno profesional, y que tiene que entregar esta documentación para comentar lo que ha descubierto (datos de entrada, rendimiento de los modelos, o cualquier descubrimiento que pueda ser importante). Comente los resultados obtenidos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Lea el contenido del fichero csv en un DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham              Will Ì_ b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"spam.csv\", sep=',')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Realice el pre-procesamiento que considere necesario. Puede utilizar funciones de la librería NLTK o spaCy, a su voluntad. Recomendamos una escritura modular del código, para poder hacer pruebas posteriormente, y contestar a las preguntas del punto 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df.text.to_list()\n",
    "\n",
    "def limpiar_texto(texto):\n",
    "    if not isinstance(texto, str):\n",
    "        raise ValueError(\"El argumento 'texto' debe ser una cadena de texto.\")\n",
    "    \n",
    "    # Eliminar caracteres especiales y números\n",
    "    texto = re.sub(r'[^a-zA-Z\\s]', '', texto)\n",
    "    \n",
    "    # Convertir a minúsculas\n",
    "    texto = texto.lower()\n",
    "    \n",
    "    # Tokenizar el texto\n",
    "    tokens = word_tokenize(texto)\n",
    "    \n",
    "    # Eliminar stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens_filtrados = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Unir tokens nuevamente en un string\n",
    "    texto_limpiado = ' '.join(tokens_filtrados)\n",
    "    \n",
    "    return texto_limpiado\n",
    "\n",
    "def limpiar_corpus(corpus):\n",
    "    corpus_limpiado = []\n",
    "    \n",
    "    for email in corpus:\n",
    "        try:\n",
    "            email_limpiado = limpiar_texto(email)\n",
    "            corpus_limpiado.append(email_limpiado)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            corpus_limpiado.append('error')\n",
    "    \n",
    "    return corpus_limpiado\n",
    "\n",
    "# Llamar a la función para limpiar el corpus\n",
    "corpus_limpiado = limpiar_corpus(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>corpus_limpiado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry wkly comp win fa cup final tkts st ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah dont think goes usf lives around though</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>nd time tried contact u u pound prize claim ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>b going esplanade fr home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>pity mood soany suggestions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>guy bitching acted like id interested buying s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>rofl true name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text  \\\n",
       "0      ham  Go until jurong point, crazy.. Available only ...   \n",
       "1      ham                      Ok lar... Joking wif u oni...   \n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3      ham  U dun say so early hor... U c already then say...   \n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "...    ...                                                ...   \n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...   \n",
       "5568   ham              Will Ì_ b going to esplanade fr home?   \n",
       "5569   ham  Pity, * was in mood for that. So...any other s...   \n",
       "5570   ham  The guy did some bitching but I acted like i'd...   \n",
       "5571   ham                         Rofl. Its true to its name   \n",
       "\n",
       "                                        corpus_limpiado  \n",
       "0     go jurong point crazy available bugis n great ...  \n",
       "1                               ok lar joking wif u oni  \n",
       "2     free entry wkly comp win fa cup final tkts st ...  \n",
       "3                   u dun say early hor u c already say  \n",
       "4           nah dont think goes usf lives around though  \n",
       "...                                                 ...  \n",
       "5567  nd time tried contact u u pound prize claim ea...  \n",
       "5568                          b going esplanade fr home  \n",
       "5569                        pity mood soany suggestions  \n",
       "5570  guy bitching acted like id interested buying s...  \n",
       "5571                                     rofl true name  \n",
       "\n",
       "[5572 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['corpus_limpiado'] = df['text'].apply(lambda x: limpiar_texto(x))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Convierta el corpus de documentos en una matriz TF-idf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aah</th>\n",
       "      <th>aaniye</th>\n",
       "      <th>aaooooright</th>\n",
       "      <th>aathilove</th>\n",
       "      <th>aathiwhere</th>\n",
       "      <th>ab</th>\n",
       "      <th>abbey</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>abeg</th>\n",
       "      <th>...</th>\n",
       "      <th>zeros</th>\n",
       "      <th>zf</th>\n",
       "      <th>zhong</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtorius</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zs</th>\n",
       "      <th>zyada</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>go jurong point crazy available bugis n great world la e buffet cine got amore wat</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ok lar joking wif u oni</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>free entry wkly comp win fa cup final tkts st may text fa receive entry questionstd txt ratetcs apply overs</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u dun say early hor u c already say</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nah dont think goes usf lives around though</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nd time tried contact u u pound prize claim easy call p per minute btnationalrate</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b going esplanade fr home</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pity mood soany suggestions</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guy bitching acted like id interested buying something else next week gave us free</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rofl true name</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 8385 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     aa  aah  aaniye  \\\n",
       "go jurong point crazy available bugis n great w...  0.0  0.0     0.0   \n",
       "ok lar joking wif u oni                             0.0  0.0     0.0   \n",
       "free entry wkly comp win fa cup final tkts st m...  0.0  0.0     0.0   \n",
       "u dun say early hor u c already say                 0.0  0.0     0.0   \n",
       "nah dont think goes usf lives around though         0.0  0.0     0.0   \n",
       "...                                                 ...  ...     ...   \n",
       "nd time tried contact u u pound prize claim eas...  0.0  0.0     0.0   \n",
       "b going esplanade fr home                           0.0  0.0     0.0   \n",
       "pity mood soany suggestions                         0.0  0.0     0.0   \n",
       "guy bitching acted like id interested buying so...  0.0  0.0     0.0   \n",
       "rofl true name                                      0.0  0.0     0.0   \n",
       "\n",
       "                                                    aaooooright  aathilove  \\\n",
       "go jurong point crazy available bugis n great w...          0.0        0.0   \n",
       "ok lar joking wif u oni                                     0.0        0.0   \n",
       "free entry wkly comp win fa cup final tkts st m...          0.0        0.0   \n",
       "u dun say early hor u c already say                         0.0        0.0   \n",
       "nah dont think goes usf lives around though                 0.0        0.0   \n",
       "...                                                         ...        ...   \n",
       "nd time tried contact u u pound prize claim eas...          0.0        0.0   \n",
       "b going esplanade fr home                                   0.0        0.0   \n",
       "pity mood soany suggestions                                 0.0        0.0   \n",
       "guy bitching acted like id interested buying so...          0.0        0.0   \n",
       "rofl true name                                              0.0        0.0   \n",
       "\n",
       "                                                    aathiwhere   ab  abbey  \\\n",
       "go jurong point crazy available bugis n great w...         0.0  0.0    0.0   \n",
       "ok lar joking wif u oni                                    0.0  0.0    0.0   \n",
       "free entry wkly comp win fa cup final tkts st m...         0.0  0.0    0.0   \n",
       "u dun say early hor u c already say                        0.0  0.0    0.0   \n",
       "nah dont think goes usf lives around though                0.0  0.0    0.0   \n",
       "...                                                        ...  ...    ...   \n",
       "nd time tried contact u u pound prize claim eas...         0.0  0.0    0.0   \n",
       "b going esplanade fr home                                  0.0  0.0    0.0   \n",
       "pity mood soany suggestions                                0.0  0.0    0.0   \n",
       "guy bitching acted like id interested buying so...         0.0  0.0    0.0   \n",
       "rofl true name                                             0.0  0.0    0.0   \n",
       "\n",
       "                                                    abdomen  abeg  ...  zeros  \\\n",
       "go jurong point crazy available bugis n great w...      0.0   0.0  ...    0.0   \n",
       "ok lar joking wif u oni                                 0.0   0.0  ...    0.0   \n",
       "free entry wkly comp win fa cup final tkts st m...      0.0   0.0  ...    0.0   \n",
       "u dun say early hor u c already say                     0.0   0.0  ...    0.0   \n",
       "nah dont think goes usf lives around though             0.0   0.0  ...    0.0   \n",
       "...                                                     ...   ...  ...    ...   \n",
       "nd time tried contact u u pound prize claim eas...      0.0   0.0  ...    0.0   \n",
       "b going esplanade fr home                               0.0   0.0  ...    0.0   \n",
       "pity mood soany suggestions                             0.0   0.0  ...    0.0   \n",
       "guy bitching acted like id interested buying so...      0.0   0.0  ...    0.0   \n",
       "rofl true name                                          0.0   0.0  ...    0.0   \n",
       "\n",
       "                                                     zf  zhong  zindgi  zoe  \\\n",
       "go jurong point crazy available bugis n great w...  0.0    0.0     0.0  0.0   \n",
       "ok lar joking wif u oni                             0.0    0.0     0.0  0.0   \n",
       "free entry wkly comp win fa cup final tkts st m...  0.0    0.0     0.0  0.0   \n",
       "u dun say early hor u c already say                 0.0    0.0     0.0  0.0   \n",
       "nah dont think goes usf lives around though         0.0    0.0     0.0  0.0   \n",
       "...                                                 ...    ...     ...  ...   \n",
       "nd time tried contact u u pound prize claim eas...  0.0    0.0     0.0  0.0   \n",
       "b going esplanade fr home                           0.0    0.0     0.0  0.0   \n",
       "pity mood soany suggestions                         0.0    0.0     0.0  0.0   \n",
       "guy bitching acted like id interested buying so...  0.0    0.0     0.0  0.0   \n",
       "rofl true name                                      0.0    0.0     0.0  0.0   \n",
       "\n",
       "                                                    zogtorius  zoom  zouk  \\\n",
       "go jurong point crazy available bugis n great w...        0.0   0.0   0.0   \n",
       "ok lar joking wif u oni                                   0.0   0.0   0.0   \n",
       "free entry wkly comp win fa cup final tkts st m...        0.0   0.0   0.0   \n",
       "u dun say early hor u c already say                       0.0   0.0   0.0   \n",
       "nah dont think goes usf lives around though               0.0   0.0   0.0   \n",
       "...                                                       ...   ...   ...   \n",
       "nd time tried contact u u pound prize claim eas...        0.0   0.0   0.0   \n",
       "b going esplanade fr home                                 0.0   0.0   0.0   \n",
       "pity mood soany suggestions                               0.0   0.0   0.0   \n",
       "guy bitching acted like id interested buying so...        0.0   0.0   0.0   \n",
       "rofl true name                                            0.0   0.0   0.0   \n",
       "\n",
       "                                                     zs  zyada  \n",
       "go jurong point crazy available bugis n great w...  0.0    0.0  \n",
       "ok lar joking wif u oni                             0.0    0.0  \n",
       "free entry wkly comp win fa cup final tkts st m...  0.0    0.0  \n",
       "u dun say early hor u c already say                 0.0    0.0  \n",
       "nah dont think goes usf lives around though         0.0    0.0  \n",
       "...                                                 ...    ...  \n",
       "nd time tried contact u u pound prize claim eas...  0.0    0.0  \n",
       "b going esplanade fr home                           0.0    0.0  \n",
       "pity mood soany suggestions                         0.0    0.0  \n",
       "guy bitching acted like id interested buying so...  0.0    0.0  \n",
       "rofl true name                                      0.0    0.0  \n",
       "\n",
       "[5572 rows x 8385 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crear una instancia de TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Ajustar el vectorizador a los argumentos preprocesados y transformar los datos\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(corpus_limpiado)\n",
    "\n",
    "# Convertir la matriz X_tfidf a un DataFrame de pandas\n",
    "df_tfidf = pd.DataFrame(X_tfidf.toarray(), columns=tfidf_vectorizer.get_feature_names_out(), index=corpus_limpiado)\n",
    "\n",
    "# df_tfidf ahora contiene la representación TF-IDF en formato DataFrame\n",
    "df_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Divida en un subconjunto de entrenamiento y otro de evaluación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_num = 100\n",
    "train_df, test_df = train_test_split(df, test_size=0.3, random_state=random_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Llegados a este punto, realice modelos de entrenamiento al menos con algoritmos de clasificador bayesiano ingenuo, máquinas SVM y un modelo basado en árbol de decisión. Obtenga resultados de accuracy de la clasificación, así como las matrices de confusión para los tres modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
